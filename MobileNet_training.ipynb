{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42a0695b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8bed51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some hyperparameters\n",
    "batch_size = 32\n",
    "epochs = 30\n",
    "num_classes = 15\n",
    "img_width, img_height = 224, 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "904a999b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ImageDataGenerator to load the images and apply data augmentation\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7124c893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5536 images belonging to 15 classes.\n",
      "Found 686 images belonging to 15 classes.\n",
      "Found 706 images belonging to 15 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load the data from the directories\n",
    "train_data = train_datagen.flow_from_directory(\n",
    "    'split_data/train',\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_data = val_datagen.flow_from_directory(\n",
    "    'split_data/val',\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_data = val_datagen.flow_from_directory(\n",
    "    'split_data/test',\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a42fcea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained MobileNet model with pre-trained weights from ImageNet\n",
    "base_model = MobileNet(input_shape=(img_width, img_height, 3), include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0324672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the pre-trained layers to prevent their weights from being updated during training\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad1cd56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new classification layer to the top of the pre-trained model\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5adf5b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with an appropriate optimizer and loss function\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb06c508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "173/173 [==============================] - 181s 1s/step - loss: 1.8533 - accuracy: 0.3866 - val_loss: 1.6816 - val_accuracy: 0.4067\n",
      "Epoch 2/30\n",
      "173/173 [==============================] - 180s 1s/step - loss: 1.4794 - accuracy: 0.4910 - val_loss: 1.5713 - val_accuracy: 0.4723\n",
      "Epoch 3/30\n",
      "173/173 [==============================] - 164s 946ms/step - loss: 1.3707 - accuracy: 0.5325 - val_loss: 1.6265 - val_accuracy: 0.4315\n",
      "Epoch 4/30\n",
      "173/173 [==============================] - 156s 901ms/step - loss: 1.3101 - accuracy: 0.5461 - val_loss: 1.6260 - val_accuracy: 0.4242\n",
      "Epoch 5/30\n",
      "173/173 [==============================] - 177s 1s/step - loss: 1.2430 - accuracy: 0.5746 - val_loss: 1.4608 - val_accuracy: 0.4985\n",
      "Epoch 6/30\n",
      "173/173 [==============================] - 173s 1000ms/step - loss: 1.2533 - accuracy: 0.5750 - val_loss: 1.4825 - val_accuracy: 0.5117\n",
      "Epoch 7/30\n",
      "173/173 [==============================] - 170s 981ms/step - loss: 1.1756 - accuracy: 0.5990 - val_loss: 1.4195 - val_accuracy: 0.5204\n",
      "Epoch 8/30\n",
      "173/173 [==============================] - 168s 973ms/step - loss: 1.1610 - accuracy: 0.6082 - val_loss: 1.3947 - val_accuracy: 0.5335\n",
      "Epoch 9/30\n",
      "173/173 [==============================] - 165s 953ms/step - loss: 1.1382 - accuracy: 0.6129 - val_loss: 1.3502 - val_accuracy: 0.5452\n",
      "Epoch 10/30\n",
      "173/173 [==============================] - 165s 954ms/step - loss: 1.1112 - accuracy: 0.6152 - val_loss: 1.5285 - val_accuracy: 0.4869\n",
      "Epoch 11/30\n",
      "173/173 [==============================] - 173s 1s/step - loss: 1.0811 - accuracy: 0.6292 - val_loss: 1.3940 - val_accuracy: 0.5364\n",
      "Epoch 12/30\n",
      "173/173 [==============================] - 168s 968ms/step - loss: 1.0738 - accuracy: 0.6328 - val_loss: 1.4762 - val_accuracy: 0.4898\n",
      "Epoch 13/30\n",
      "173/173 [==============================] - 168s 970ms/step - loss: 1.0389 - accuracy: 0.6326 - val_loss: 1.4343 - val_accuracy: 0.5058\n",
      "Epoch 14/30\n",
      "173/173 [==============================] - 166s 960ms/step - loss: 1.0262 - accuracy: 0.6458 - val_loss: 1.4725 - val_accuracy: 0.4854\n",
      "Epoch 15/30\n",
      "173/173 [==============================] - 164s 947ms/step - loss: 1.0071 - accuracy: 0.6505 - val_loss: 1.4977 - val_accuracy: 0.5131\n",
      "Epoch 16/30\n",
      "173/173 [==============================] - 166s 960ms/step - loss: 0.9875 - accuracy: 0.6591 - val_loss: 1.5253 - val_accuracy: 0.4883\n",
      "Epoch 17/30\n",
      "173/173 [==============================] - 167s 967ms/step - loss: 0.9933 - accuracy: 0.6653 - val_loss: 1.5132 - val_accuracy: 0.4942\n",
      "Epoch 18/30\n",
      "173/173 [==============================] - 170s 983ms/step - loss: 0.9729 - accuracy: 0.6665 - val_loss: 1.4219 - val_accuracy: 0.5146\n",
      "Epoch 19/30\n",
      "173/173 [==============================] - 169s 978ms/step - loss: 0.9506 - accuracy: 0.6664 - val_loss: 1.3616 - val_accuracy: 0.5219\n",
      "Epoch 20/30\n",
      "173/173 [==============================] - 166s 959ms/step - loss: 0.9459 - accuracy: 0.6700 - val_loss: 1.4498 - val_accuracy: 0.5131\n",
      "Epoch 21/30\n",
      "173/173 [==============================] - 168s 973ms/step - loss: 0.9233 - accuracy: 0.6817 - val_loss: 1.5508 - val_accuracy: 0.4869\n",
      "Epoch 22/30\n",
      "173/173 [==============================] - 168s 970ms/step - loss: 0.9156 - accuracy: 0.6808 - val_loss: 1.4333 - val_accuracy: 0.5044\n",
      "Epoch 23/30\n",
      "173/173 [==============================] - 167s 963ms/step - loss: 0.9113 - accuracy: 0.6870 - val_loss: 1.3976 - val_accuracy: 0.5481\n",
      "Epoch 24/30\n",
      "173/173 [==============================] - 172s 996ms/step - loss: 0.8877 - accuracy: 0.6935 - val_loss: 1.3555 - val_accuracy: 0.5510\n",
      "Epoch 25/30\n",
      "173/173 [==============================] - 168s 970ms/step - loss: 0.8730 - accuracy: 0.6947 - val_loss: 1.5748 - val_accuracy: 0.4796\n",
      "Epoch 26/30\n",
      "173/173 [==============================] - 167s 967ms/step - loss: 0.8499 - accuracy: 0.7072 - val_loss: 1.4733 - val_accuracy: 0.5248\n",
      "Epoch 27/30\n",
      "173/173 [==============================] - 148s 857ms/step - loss: 0.8485 - accuracy: 0.7057 - val_loss: 1.4884 - val_accuracy: 0.4956\n",
      "Epoch 28/30\n",
      "173/173 [==============================] - 150s 867ms/step - loss: 0.8345 - accuracy: 0.7065 - val_loss: 1.4463 - val_accuracy: 0.5087\n",
      "Epoch 29/30\n",
      "173/173 [==============================] - 149s 862ms/step - loss: 0.8199 - accuracy: 0.7155 - val_loss: 1.5017 - val_accuracy: 0.5146\n",
      "Epoch 30/30\n",
      "173/173 [==============================] - 150s 864ms/step - loss: 0.8269 - accuracy: 0.7068 - val_loss: 1.5670 - val_accuracy: 0.4825\n"
     ]
    }
   ],
   "source": [
    "# Train the model on your training data\n",
    "history = model.fit(train_data, epochs=epochs, validation_data=val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d34e1d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 15s 645ms/step - loss: 1.4336 - accuracy: 0.5425\n",
      "Test accuracy: 0.5424929261207581\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on your test data\n",
    "test_loss, test_acc = model.evaluate(test_data)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cec72f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-multilearn in c:\\python39\\lib\\site-packages (0.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the 'C:\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-multilearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e1802063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 14s 582ms/step - loss: 1.4336 - accuracy: 0.5425\n",
      "23/23 [==============================] - 12s 525ms/step\n",
      "LWLRAP score: 0.29308048341334453\n",
      "Top-5 categorical accuracy: 0.48441926345609065\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import label_ranking_average_precision_score\n",
    "from sklearn.metrics import top_k_accuracy_score\n",
    "\n",
    "# Evaluate the model on the test set and make predictions\n",
    "test_loss, test_acc = model.evaluate(test_data)\n",
    "y_pred = model.predict(test_data)\n",
    "\n",
    "# Compute LWLRAP score\n",
    "y_true = to_categorical(test_data.labels, num_classes=15)\n",
    "lwlrAP = label_ranking_average_precision_score(y_true, y_pred)\n",
    "print('LWLRAP score:', lwlrAP)\n",
    "\n",
    "# Compute top-5 categorical accuracy\n",
    "top5_accuracy = top_k_accuracy_score(test_data.labels, y_pred, k=5)\n",
    "print('Top-5 categorical accuracy:', top5_accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
