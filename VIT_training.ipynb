{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9b42fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-addons\n",
      "  Using cached tensorflow_addons-0.20.0-cp39-cp39-win_amd64.whl (746 kB)\n",
      "Collecting typeguard<3.0.0,>=2.7\n",
      "  Using cached typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\arham\\anaconda3\\lib\\site-packages (from tensorflow-addons) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\arham\\anaconda3\\lib\\site-packages (from packaging->tensorflow-addons) (3.0.9)\n",
      "Installing collected packages: typeguard, tensorflow-addons\n",
      "Successfully installed tensorflow-addons-0.20.0 typeguard-2.13.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de22a084",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "135723b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained ResNet50 model\n",
    "resnet = keras.applications.ResNet50(include_top=False, weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f5ff202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ViT model\n",
    "input_shape = (224, 224, 3)\n",
    "num_classes = 15\n",
    "\n",
    "inputs = keras.Input(shape=input_shape)\n",
    "x = layers.experimental.preprocessing.Rescaling(scale=1./255)(inputs)\n",
    "x = layers.experimental.preprocessing.RandomFlip(\"horizontal\")(x)\n",
    "x = layers.experimental.preprocessing.RandomRotation(0.1)(x)\n",
    "x = resnet(x, training=False)  # use ResNet50 as a feature extractor\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(256, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "vit_classifier = keras.Model(inputs, outputs, name=\"vit_classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d284723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer and other hyperparameters\n",
    "learning_rate = 1e-4\n",
    "weight_decay = 1e-4\n",
    "batch_size = 32\n",
    "num_epochs = 15\n",
    "\n",
    "optimizer = tfa.optimizers.AdamW(\n",
    "    learning_rate=learning_rate, weight_decay=weight_decay\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63d05eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "vit_classifier.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\n",
    "        keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
    "        keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ba70369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4991 images belonging to 15 classes.\n",
      "Found 545 images belonging to 15 classes.\n",
      "Found 706 images belonging to 15 classes.\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data\n",
    "train_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=0.1,\n",
    "    validation_split=0.1\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    \"split_data/train\",\n",
    "    target_size=input_shape[:2],\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"sparse\",\n",
    "    shuffle=True,\n",
    "    subset=\"training\",\n",
    ")\n",
    "\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    \"split_data/train\",\n",
    "    target_size=input_shape[:2],\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"sparse\",\n",
    "    shuffle=False,\n",
    "    subset=\"validation\",\n",
    ")\n",
    "\n",
    "test_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    \"split_data/test\",\n",
    "    target_size=input_shape[:2],\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"sparse\",\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6c14306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\keras\\backend.py:5612: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156/156 [==============================] - 1466s 9s/step - loss: 2.4739 - accuracy: 0.1573 - top-5-accuracy: 0.6241 - val_loss: 2.3551 - val_accuracy: 0.1927 - val_top-5-accuracy: 0.6789\n",
      "Epoch 2/15\n",
      "156/156 [==============================] - 1381s 9s/step - loss: 2.4322 - accuracy: 0.1631 - top-5-accuracy: 0.6458 - val_loss: 2.3436 - val_accuracy: 0.1927 - val_top-5-accuracy: 0.6771\n",
      "Epoch 3/15\n",
      "156/156 [==============================] - 1348s 9s/step - loss: 2.4102 - accuracy: 0.1699 - top-5-accuracy: 0.6560 - val_loss: 2.3487 - val_accuracy: 0.1927 - val_top-5-accuracy: 0.6771\n",
      "Epoch 4/15\n",
      "156/156 [==============================] - 1341s 9s/step - loss: 2.4086 - accuracy: 0.1771 - top-5-accuracy: 0.6562 - val_loss: 2.3708 - val_accuracy: 0.1927 - val_top-5-accuracy: 0.6771\n",
      "Epoch 5/15\n",
      "156/156 [==============================] - 1349s 9s/step - loss: 2.4017 - accuracy: 0.1749 - top-5-accuracy: 0.6542 - val_loss: 2.3324 - val_accuracy: 0.1927 - val_top-5-accuracy: 0.6771\n",
      "Epoch 6/15\n",
      "156/156 [==============================] - 1352s 9s/step - loss: 2.3929 - accuracy: 0.1707 - top-5-accuracy: 0.6552 - val_loss: 2.3345 - val_accuracy: 0.1927 - val_top-5-accuracy: 0.6771\n",
      "Epoch 7/15\n",
      "156/156 [==============================] - 1358s 9s/step - loss: 2.3831 - accuracy: 0.1711 - top-5-accuracy: 0.6602 - val_loss: 2.3604 - val_accuracy: 0.1927 - val_top-5-accuracy: 0.6771\n",
      "Epoch 8/15\n",
      "156/156 [==============================] - 1354s 9s/step - loss: 2.3772 - accuracy: 0.1777 - top-5-accuracy: 0.6630 - val_loss: 2.3331 - val_accuracy: 0.1927 - val_top-5-accuracy: 0.6789\n",
      "Epoch 9/15\n",
      "156/156 [==============================] - 1355s 9s/step - loss: 2.3798 - accuracy: 0.1765 - top-5-accuracy: 0.6652 - val_loss: 2.3304 - val_accuracy: 0.1927 - val_top-5-accuracy: 0.6771\n",
      "Epoch 10/15\n",
      "156/156 [==============================] - 1357s 9s/step - loss: 2.3790 - accuracy: 0.1727 - top-5-accuracy: 0.6552 - val_loss: 2.3278 - val_accuracy: 0.1927 - val_top-5-accuracy: 0.6789\n",
      "Epoch 11/15\n",
      "156/156 [==============================] - 1346s 9s/step - loss: 2.3811 - accuracy: 0.1783 - top-5-accuracy: 0.6560 - val_loss: 2.3367 - val_accuracy: 0.1927 - val_top-5-accuracy: 0.6771\n",
      "Epoch 12/15\n",
      "156/156 [==============================] - 1373s 9s/step - loss: 2.3768 - accuracy: 0.1715 - top-5-accuracy: 0.6608 - val_loss: 2.3256 - val_accuracy: 0.1927 - val_top-5-accuracy: 0.6771\n",
      "Epoch 13/15\n",
      "156/156 [==============================] - 1355s 9s/step - loss: 2.3715 - accuracy: 0.1743 - top-5-accuracy: 0.6644 - val_loss: 2.3315 - val_accuracy: 0.1927 - val_top-5-accuracy: 0.6771\n",
      "Epoch 14/15\n",
      "156/156 [==============================] - 1351s 9s/step - loss: 2.3744 - accuracy: 0.1687 - top-5-accuracy: 0.6706 - val_loss: 2.3338 - val_accuracy: 0.1927 - val_top-5-accuracy: 0.6771\n",
      "Epoch 15/15\n",
      "156/156 [==============================] - 1383s 9s/step - loss: 2.3766 - accuracy: 0.1759 - top-5-accuracy: 0.6558 - val_loss: 2.3254 - val_accuracy: 0.1927 - val_top-5-accuracy: 0.6771\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow import keras\n",
    "\n",
    "# Create a directory for the model checkpoint\n",
    "checkpoint_dir = \"./my_checkpoint_directory\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# Set the checkpoint file path\n",
    "checkpoint_filepath = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "\n",
    "# Create a ModelCheckpoint callback to save the best weights\n",
    "checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    checkpoint_filepath,\n",
    "    monitor=\"val_accuracy\",\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    ")\n",
    "\n",
    "# Train the model with the checkpoint callback\n",
    "history = vit_classifier.fit(\n",
    "    train_generator,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[checkpoint_callback],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc287cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 56s 2s/step - loss: 2.3864 - accuracy: 0.1884 - top-5-accuracy: 0.6657\n",
      "Test accuracy: 18.84%\n",
      "Test top 5 accuracy: 66.57%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model epoc 15 \n",
    "vit_classifier.load_weights(checkpoint_filepath)\n",
    "_, accuracy, top_5_accuracy = vit_classifier.evaluate(test_generator)\n",
    "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bda66ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 41s 2s/step - loss: 2.3775 - accuracy: 0.1884 - top-5-accuracy: 0.6643\n",
      "Test accuracy: 18.84%\n",
      "Test top 5 accuracy: 66.43%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "vit_classifier.load_weights(checkpoint_filepath)\n",
    "_, accuracy, top_5_accuracy = vit_classifier.evaluate(test_generator)\n",
    "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "110de27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 41s 2s/step - loss: 2.3775 - accuracy: 0.1884 - top-5-accuracy: 0.6643\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m vit_classifier\u001b[38;5;241m.\u001b[39mload_weights(checkpoint_filepath)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Evaluate the model on the test dataset\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m test_loss, test_accuracy \u001b[38;5;241m=\u001b[39m vit_classifier\u001b[38;5;241m.\u001b[39mevaluate(test_generator)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest loss:\u001b[39m\u001b[38;5;124m\"\u001b[39m, test_loss)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest accuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, test_accuracy)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# Load the best weights from the model checkpoint\n",
    "vit_classifier.load_weights(checkpoint_filepath)\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "test_loss, test_accuracy = vit_classifier.evaluate(test_generator)\n",
    "\n",
    "print(\"Test loss:\", test_loss)\n",
    "print(\"Test accuracy:\", test_accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
